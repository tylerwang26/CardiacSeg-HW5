# ğŸš€ RTX 4090 CUDA é·ç§»å®Œæ•´æŒ‡å—

## ğŸ“¦ Step 1: æª”æ¡ˆæº–å‚™ï¼ˆmacOS - å·²å®Œæˆ âœ…ï¼‰

### Checkpoint æ‰“åŒ…ç‹€æ…‹
```bash
æª”æ¡ˆï¼šnnunet_checkpoint_epoch5.tar.gz
å¤§å°ï¼š1.0 GB
ä½ç½®ï¼š/Users/tyler/Documents/GitHub/CardiacSeg/
```

### åŒ…å«å…§å®¹
- âœ… Preprocessed è³‡æ–™ï¼ˆ3d_lowres æ‰€æœ‰ .npy æª”æ¡ˆï¼‰
- âœ… Dataset é…ç½®ï¼ˆdataset.json, nnUNetPlans.json, splits_final.json ç­‰ï¼‰
- âœ… æœ€ä½³ Checkpointï¼ˆcheckpoint_best.pth - Epoch 4 å¾Œï¼ŒEMA Dice 0.3302ï¼‰
- âœ… è¨“ç·´æ—¥èªŒèˆ‡ debug è³‡è¨Š

### ç•¶å‰è¨“ç·´é€²åº¦
- **å·²å®Œæˆ**ï¼šEpoch 0-4ï¼ˆ5å€‹epochsï¼‰
- **å‰©é¤˜**ï¼šEpoch 5-80ï¼ˆ75å€‹epochsï¼‰
- **æœ€ä½³æŒ‡æ¨™**ï¼š
  - Best EMA Dice: 0.3302
  - é¡åˆ¥1 Dice: 0.888
  - é¡åˆ¥2 Dice: 0.646
  - é¡åˆ¥3 Dice: 0.000ï¼ˆå°šæœªå­¸ç¿’ï¼‰

---

## âš¡ åŠ é€Ÿæ•ˆç›Šåˆ†æ

### ç¡¬é«”å°æ¯”

| è¦æ ¼ | Apple Silicon MPS | RTX 4090 CUDA |
|------|------------------|---------------|
| **é‹ç®—æ ¸å¿ƒ** | ~40 GPU cores (M1/M2 Max) | 16,384 CUDA cores + Tensor cores |
| **è¨˜æ†¶é«”é »å¯¬** | ~400 GB/s | 1,008 GB/s |
| **VRAM** | çµ±ä¸€è¨˜æ†¶é«” 32-96 GB | 24 GB GDDR6X |
| **nnU-Net å„ªåŒ–** | åŸºæœ¬æ”¯æ´ | åŸç”Ÿæœ€ä½³åŒ– |

### é€Ÿåº¦å°æ¯”èˆ‡é ä¼°

| é …ç›® | MPS | RTX 4090 | åŠ é€Ÿæ¯” |
|------|-----|----------|--------|
| **æ¯ Epoch æ™‚é–“** | 1h 45m (6,300s) | **26 åˆ†é˜ (1,560s)** | **4.0x** |
| **å‰©é¤˜ 75 epochs** | 131 å°æ™‚ (5.5 å¤©) | **33 å°æ™‚ (1.4 å¤©)** | **4.0x** |
| **ç¸½è¨“ç·´æ™‚é–“** (80 epochs) | 140 å°æ™‚ (5.8 å¤©) | **35 å°æ™‚ (1.5 å¤©)** | **4.0x** |
| **ç¯€çœæ™‚é–“** | - | **105 å°æ™‚ (4.4 å¤©)** | - |

### é‡Œç¨‹ç¢‘æ™‚é–“è¡¨å°æ¯”

| é‡Œç¨‹ç¢‘ | MPS é ä¼°å®Œæˆ | RTX 4090 é ä¼°å®Œæˆ | ç¯€çœæ™‚é–“ |
|--------|-------------|-----------------|---------|
| Epoch 10 | 18 å°æ™‚ | **4.5 å°æ™‚** | 13.5 å°æ™‚ |
| Epoch 20 | 35 å°æ™‚ (1.5 å¤©) | **9 å°æ™‚** | 26 å°æ™‚ |
| Epoch 40 | 70 å°æ™‚ (2.9 å¤©) | **17.5 å°æ™‚** | 52.5 å°æ™‚ |
| Epoch 60 | 105 å°æ™‚ (4.4 å¤©) | **26 å°æ™‚** | 79 å°æ™‚ |
| **Epoch 80** | **140 å°æ™‚ (5.8 å¤©)** | **35 å°æ™‚ (1.5 å¤©)** | **105 å°æ™‚** |

---

## ğŸ”§ Step 2: åœæ­¢ macOS è¨“ç·´

### 2.1 æª¢æŸ¥ç•¶å‰è¨“ç·´ç‹€æ…‹
```bash
ps -Ao pid,pcpu,pmem,etime,command | grep -Ei 'nnunet' | grep -v grep
```

### 2.2 å„ªé›…åœæ­¢è¨“ç·´
```bash
# æ‰¾åˆ°è¨“ç·´é€²ç¨‹ PIDï¼ˆä¾‹å¦‚ 19223ï¼‰
PID=$(pgrep -f "nnunetv2.run.run_training.*3d_lowres")

# ç™¼é€ SIGINTï¼ˆå„ªé›…åœæ­¢ï¼Œæœƒä¿å­˜ checkpointï¼‰
kill -SIGINT $PID

# ç­‰å¾… 10 ç§’
sleep 10

# å¦‚æœé‚„åœ¨é‹è¡Œï¼Œå¼·åˆ¶åœæ­¢
if ps -p $PID > /dev/null 2>&1; then
    kill -SIGKILL $PID
fi

echo "âœ… è¨“ç·´å·²åœæ­¢"
```

### 2.3 ç¢ºèªæœ€çµ‚ç‹€æ…‹
```bash
# ç¢ºèªé€²ç¨‹å·²çµæŸ
ps -p $PID 2>/dev/null || echo "é€²ç¨‹å·²çµæŸ"

# æª¢æŸ¥æœ€å¾Œçš„ checkpoint æ™‚é–“
ls -lh nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/checkpoint_best.pth
```

---

## ğŸ“¤ Step 3: å‚³è¼¸æª”æ¡ˆåˆ° RTX 4090 æ©Ÿå™¨

### 3.1 ä½¿ç”¨ scp å‚³è¼¸ï¼ˆæ¨è–¦ï¼‰
```bash
# åœ¨ macOS ä¸ŠåŸ·è¡Œ
cd /Users/tyler/Documents/GitHub/CardiacSeg

# å‚³è¼¸æ‰“åŒ…æª”æ¡ˆï¼ˆæ›¿æ› user@rtx-machine ç‚ºå¯¦éš›ä½å€ï¼‰
scp nnunet_checkpoint_epoch5.tar.gz user@rtx-machine:/path/to/destination/

# å‚³è¼¸è¨“ç·´è…³æœ¬èˆ‡ç›£æ§è…³æœ¬
scp nnunet_train.py monitor_and_stop.sh user@rtx-machine:/path/to/destination/
```

### 3.2 æˆ–ä½¿ç”¨ rsyncï¼ˆçºŒå‚³æ”¯æ´ï¼‰
```bash
rsync -avz --progress nnunet_checkpoint_epoch5.tar.gz user@rtx-machine:/path/to/destination/
```

### 3.3 æˆ–ä½¿ç”¨é›²ç«¯ç¡¬ç¢Ÿ/USB
```bash
# è¤‡è£½åˆ°å¤–æ¥ç¡¬ç¢Ÿ
cp nnunet_checkpoint_epoch5.tar.gz /Volumes/USB_DRIVE/

# åœ¨ RTX 4090 æ©Ÿå™¨ä¸Šæ›è¼‰ä¸¦è¤‡è£½
```

---

## ğŸ–¥ï¸ Step 4: RTX 4090 æ©Ÿå™¨ç’°å¢ƒè¨­å®š

### 4.1 ç¢ºèª CUDA ç’°å¢ƒ
```bash
# æª¢æŸ¥ NVIDIA é©…å‹•èˆ‡ CUDA
nvidia-smi

# æ‡‰é¡¯ç¤ºé¡ä¼¼ï¼š
# GPU: NVIDIA GeForce RTX 4090
# CUDA Version: 12.x
```

### 4.2 å»ºç«‹ Python è™›æ“¬ç’°å¢ƒ
```bash
# å»ºè­°ä½¿ç”¨ Python 3.10 æˆ– 3.11
python3.11 -m venv ~/nnunet_venv
source ~/nnunet_venv/bin/activate

# ç¢ºèª Python ç‰ˆæœ¬
python --version  # æ‡‰é¡¯ç¤º Python 3.11.x
```

### 4.3 å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch
```bash
# å®‰è£ PyTorch with CUDA 12.1ï¼ˆæ ¹æ“šä½ çš„ CUDA ç‰ˆæœ¬èª¿æ•´ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# é©—è­‰ CUDA å¯ç”¨
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'GPU: {torch.cuda.get_device_name(0)}')"

# æ‡‰è¼¸å‡ºï¼š
# CUDA available: True
# CUDA version: 12.1
# GPU: NVIDIA GeForce RTX 4090
```

### 4.4 å®‰è£ nnU-Net v2
```bash
# å®‰è£ nnU-Net
pip install nnunetv2

# æˆ–å¾æºç¢¼å®‰è£ï¼ˆå–å¾—æœ€æ–°ç‰ˆæœ¬ï¼‰
# git clone https://github.com/MIC-DKFZ/nnUNet.git
# cd nnUNet
# pip install -e .

# ç¢ºèªå®‰è£
nnUNetv2_train --version
```

### 4.5 è¨­å®š nnU-Net ç’°å¢ƒè®Šæ•¸
```bash
# å»ºç«‹ç›®éŒ„
mkdir -p ~/nnunet_data/{raw,preprocessed,results}

# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆåŠ å…¥åˆ° ~/.bashrc æˆ– ~/.zshrcï¼‰
export nnUNet_raw="$HOME/nnunet_data/raw"
export nnUNet_preprocessed="$HOME/nnunet_data/preprocessed"
export nnUNet_results="$HOME/nnunet_data/results"

# ç«‹å³ç”Ÿæ•ˆ
source ~/.bashrc  # æˆ– source ~/.zshrc
```

---

## ğŸ“‚ Step 5: è§£å£“èˆ‡é…ç½® Checkpoint

### 5.1 è§£å£“æª”æ¡ˆ
```bash
cd ~/nnunet_data

# è§£å£“ checkpointï¼ˆæœƒè‡ªå‹•å»ºç«‹ç›®éŒ„çµæ§‹ï¼‰
tar -xzf nnunet_checkpoint_epoch5.tar.gz

# ç¢ºèªè§£å£“æˆåŠŸ
ls -lh nnUNet_preprocessed/Dataset001_CardiacSeg/
ls -lh nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/
```

### 5.2 é©—è­‰å¿…è¦æª”æ¡ˆå­˜åœ¨
```bash
# æª¢æŸ¥ preprocessed è³‡æ–™
ls nnUNet_preprocessed/Dataset001_CardiacSeg/nnUNetPlans_3d_lowres/*.npy | wc -l
# æ‡‰é¡¯ç¤º 100 å€‹æª”æ¡ˆï¼ˆ50 training + 50 segï¼‰

# æª¢æŸ¥ checkpoint
ls -lh nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/checkpoint_best.pth
# æ‡‰é¡¯ç¤º ~235 MB

# æª¢æŸ¥é…ç½®æª”
cat nnUNet_preprocessed/Dataset001_CardiacSeg/nnUNetPlans.json | jq '.configurations."3d_lowres".batch_size'
# æ‡‰é¡¯ç¤º 2ï¼ˆé è¨­ï¼‰
```

### 5.3 ï¼ˆå¯é¸ï¼‰èª¿æ•´ batch size
```bash
# ç·¨è¼¯ nnUNetPlans.jsonï¼Œå°‡ batch_size å¾ 2 å¢åŠ åˆ° 4
cd nnUNet_preprocessed/Dataset001_CardiacSeg/
cp nnUNetPlans.json nnUNetPlans.json.bak  # å‚™ä»½

# ä½¿ç”¨ sed æˆ–æ‰‹å‹•ç·¨è¼¯
# å°‡ "batch_size": 2 æ”¹ç‚º "batch_size": 4
nano nnUNetPlans.json  # æˆ–ä½¿ç”¨ vim/code

# æ³¨æ„ï¼šbatch_size=4 éœ€è¦ç´„ 16-18 GB VRAMï¼ŒRTX 4090 24GB è¶³å¤ 
# è‹¥è¦æ›´æ¿€é€²ï¼Œå¯ä»¥è©¦ batch_size=6ï¼ˆéœ€ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨ï¼‰
```

---

## ğŸš€ Step 6: å•Ÿå‹• RTX 4090 è¨“ç·´

### 6.1 ä½¿ç”¨ nnU-Net å®˜æ–¹å‘½ä»¤ï¼ˆæ¨è–¦ï¼‰
```bash
# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
source ~/nnunet_venv/bin/activate

# åˆ‡æ›åˆ°å·¥ä½œç›®éŒ„
cd ~/nnunet_data

# å¾ checkpoint ç¹¼çºŒè¨“ç·´
nnUNetv2_train 001 3d_lowres 0 \
  -p nnUNetPlans \
  -device cuda \
  --c

# åƒæ•¸èªªæ˜ï¼š
# 001: Dataset ID
# 3d_lowres: é…ç½®åç¨±
# 0: fold ç·¨è™Ÿ
# -p nnUNetPlans: planner åç¨±
# -device cuda: ä½¿ç”¨ CUDAï¼ˆè‡ªå‹•åµæ¸¬ GPUï¼‰
# --c: ç¹¼çºŒè¨“ç·´ï¼ˆæœƒè‡ªå‹•è¼‰å…¥ checkpoint_best.pthï¼‰
```

### 6.2 æˆ–ä½¿ç”¨èƒŒæ™¯åŸ·è¡Œï¼ˆæ¨è–¦ï¼Œå¯ç™»å‡ºä¸ä¸­æ–·ï¼‰
```bash
# ä½¿ç”¨ nohup èƒŒæ™¯åŸ·è¡Œ
nohup nnUNetv2_train 001 3d_lowres 0 -p nnUNetPlans -device cuda --c > training_rtx4090.log 2>&1 &

# è¨˜ä¸‹ PID
echo $! > training_pid.txt

# æŸ¥çœ‹å³æ™‚æ—¥èªŒ
tail -f training_rtx4090.log
```

### 6.3 æˆ–ä½¿ç”¨ tmux/screenï¼ˆæ¨è–¦ï¼Œå¯éš¨æ™‚é‡æ–°é€£æ¥ï¼‰
```bash
# å®‰è£ tmuxï¼ˆå¦‚æœæ²’æœ‰ï¼‰
sudo apt install tmux  # Ubuntu/Debian
# æˆ– sudo yum install tmux  # CentOS/RHEL

# å»ºç«‹ tmux session
tmux new -s nnunet_training

# åœ¨ tmux å…§å•Ÿå‹•è¨“ç·´
source ~/nnunet_venv/bin/activate
cd ~/nnunet_data
nnUNetv2_train 001 3d_lowres 0 -p nnUNetPlans -device cuda --c

# é›¢é–‹ tmuxï¼ˆè¨“ç·´ç¹¼çºŒï¼‰ï¼šæŒ‰ Ctrl+B ç„¶å¾ŒæŒ‰ D
# é‡æ–°é€£æ¥ï¼štmux attach -t nnunet_training
```

---

## ğŸ“Š Step 7: ç›£æ§è¨“ç·´é€²åº¦

### 7.1 è¤‡è£½ä¸¦è¨­å®šç›£æ§è…³æœ¬
```bash
# ç¢ºä¿ç›£æ§è…³æœ¬å¯åŸ·è¡Œ
chmod +x monitor_and_stop.sh

# å•Ÿå‹•è‡ªå‹•ç›£æ§ï¼ˆæ¯ 15 åˆ†é˜æª¢æŸ¥ï¼Œç›®æ¨™ Dice 0.70ï¼‰
nohup ./monitor_and_stop.sh Dataset001_CardiacSeg 3d_lowres 0.70 900 > monitor_auto.log 2>&1 &

# åƒæ•¸èªªæ˜ï¼š
# Dataset001_CardiacSeg: dataset åç¨±
# 3d_lowres: é…ç½®
# 0.70: ç›®æ¨™ EMA Diceï¼ˆé”åˆ°å¾Œè‡ªå‹•åœæ­¢ï¼‰
# 900: æª¢æŸ¥é–“éš”ï¼ˆç§’ï¼Œ900=15åˆ†é˜ï¼‰
```

### 7.2 æ‰‹å‹•æŸ¥çœ‹é€²åº¦
```bash
# æŸ¥çœ‹æœ€æ–°è¨“ç·´æ—¥èªŒ
tail -n 50 nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/training_log_*.txt

# æŸ¥çœ‹é€²åº¦åœ–ï¼ˆéœ€è¦ X11 forwarding æˆ–ä¸‹è¼‰åˆ°æœ¬æ©Ÿï¼‰
# åœ¨æœ¬æ©Ÿï¼ˆmacOSï¼‰ï¼š
scp user@rtx-machine:~/nnunet_data/nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/progress.png ~/Desktop/
open ~/Desktop/progress.png

# æŸ¥çœ‹ GPU ä½¿ç”¨ç‡
watch -n 2 nvidia-smi
```

### 7.3 æª¢æŸ¥è¨“ç·´ç‹€æ…‹
```bash
# æŸ¥çœ‹è¨“ç·´é€²ç¨‹
ps aux | grep nnUNetv2_train

# æŸ¥çœ‹ GPU è¨˜æ†¶é«”ä½¿ç”¨
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# æŸ¥çœ‹ç•¶å‰ epoch èˆ‡ EMA Dice
grep -i "epoch\|best EMA" nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/training_log_*.txt | tail -n 20
```

---

## ğŸ“… RTX 4090 è¨“ç·´æ™‚ç¨‹é ä¼°

### å‡è¨­å¾ Epoch 5 ç¹¼çºŒï¼ˆ75 å€‹ epochs å‰©é¤˜ï¼‰

| æª¢æŸ¥æ™‚é–“é» | Epoch | é ä¼°ç¶“éæ™‚é–“ | é æœŸ EMA Dice | å»ºè­°å‹•ä½œ |
|-----------|-------|------------|--------------|---------|
| **é¦–æ¬¡æª¢æŸ¥** | 10 | +2 å°æ™‚ | 0.40-0.45 | ç¢ºèª CUDA é‹è¡Œæ­£å¸¸ï¼Œç„¡éŒ¯èª¤ |
| **æ—©æœŸè©•ä¼°** | 20 | +6.5 å°æ™‚ | 0.48-0.53 | æª¢æŸ¥ loss ä¸‹é™è¶¨å‹¢ï¼ŒGPU æº«åº¦ |
| **ä¸­æœŸæª¢æŸ¥** | 40 | +15 å°æ™‚ | 0.58-0.63 | è©•ä¼°æ˜¯å¦æ¥è¿‘ç›®æ¨™ï¼Œå¯èƒ½æå‰é”æ¨™ |
| **ç›®æ¨™æª¢æŸ¥** | 50-60 | +20-23 å°æ™‚ | **0.68-0.73** | å¯èƒ½é”åˆ° 0.70ï¼Œç›£æ§è…³æœ¬æœƒè‡ªå‹•åœæ­¢ |
| **å®Œæ•´è¨“ç·´** | 80 | +33 å°æ™‚ | 0.75-0.80 | ç²å¾—æœ€ä½³æ¨¡å‹ |

### å»ºè­°æª¢æŸ¥é »ç‡
- **å‰ 10 epochs**ï¼šæ¯ 2 å°æ™‚æª¢æŸ¥ï¼ˆç¢ºä¿é †åˆ©å•Ÿå‹•ï¼‰
- **Epoch 10-40**ï¼šæ¯ 4-6 å°æ™‚æª¢æŸ¥
- **Epoch 40+**ï¼šæ¯ 6-8 å°æ™‚ï¼Œæˆ–ä¾è³´è‡ªå‹•ç›£æ§

---

## âš™ï¸ å„ªåŒ–å»ºè­°èˆ‡é€²éšé…ç½®

### 1. Batch Size èª¿æ•´
```bash
# é è¨­ batch_size=2ï¼ˆä¿å®ˆï¼ŒMPS é™åˆ¶ï¼‰
# RTX 4090 24GB VRAM å¯ä»¥å¢åŠ ï¼š

# é¸é … Aï¼šbatch_size=4ï¼ˆæ¨è–¦ï¼Œç©©å®šï¼‰
# é ä¼°è¨˜æ†¶é«”ï¼š16-18 GB
# é€Ÿåº¦æå‡ï¼š~10-15%

# é¸é … Bï¼šbatch_size=6ï¼ˆæ¿€é€²ï¼‰
# é ä¼°è¨˜æ†¶é«”ï¼š22-23 GB
# é€Ÿåº¦æå‡ï¼š~20-25%
# é¢¨éšªï¼šå¯èƒ½ OOMï¼ˆè¨˜æ†¶é«”ä¸è¶³ï¼‰

# ç·¨è¼¯é…ç½®ï¼ˆåœ¨å•Ÿå‹•è¨“ç·´å‰ï¼‰
nano nnUNet_preprocessed/Dataset001_CardiacSeg/nnUNetPlans.json
# ä¿®æ”¹ "configurations" -> "3d_lowres" -> "batch_size": 4
```

### 2. æ··åˆç²¾åº¦è¨“ç·´ï¼ˆAutomatic Mixed Precisionï¼‰
```bash
# nnU-Net v2 é è¨­å·²å•Ÿç”¨ AMP
# å¦‚æœéœ€è¦åœç”¨ï¼ˆä¸æ¨è–¦ï¼‰ï¼š
# ç·¨è¼¯è¨“ç·´è…³æœ¬æˆ–ä½¿ç”¨ç’°å¢ƒè®Šæ•¸
export NNUNET_AMP=0  # åœç”¨ AMP
```

### 3. ç›£æ§ GPU æº«åº¦èˆ‡åŠŸè€—
```bash
# å³æ™‚ç›£æ§ï¼ˆæ¯ 2 ç§’æ›´æ–°ï¼‰
watch -n 2 'nvidia-smi --query-gpu=index,name,temperature.gpu,power.draw,memory.used,memory.total,utilization.gpu --format=csv,noheader'

# RTX 4090 æ­£å¸¸ç¯„åœï¼š
# æº«åº¦ï¼š70-85Â°C
# åŠŸè€—ï¼š350-450Wï¼ˆæ»¿è¼‰ï¼‰
# GPU ä½¿ç”¨ç‡ï¼š95-100%
```

### 4. å¤š GPU è¨“ç·´ï¼ˆå¦‚æœæœ‰å¤šå¼µå¡ï¼‰
```bash
# nnU-Net v2 åŸç”Ÿæ”¯æ´ DataParallel
# ä½¿ç”¨å¤š GPU
CUDA_VISIBLE_DEVICES=0,1 nnUNetv2_train 001 3d_lowres 0 -p nnUNetPlans -device cuda --c

# æ³¨æ„ï¼š
# - batch_size æœƒè‡ªå‹•åˆ†é…åˆ°å„ GPU
# - éœ€è¦èª¿æ•´ batch_size ä»¥å……åˆ†åˆ©ç”¨ï¼ˆä¾‹å¦‚ batch_size=8 for 2 GPUsï¼‰
```

### 5. ææ—©åœæ­¢ç­–ç•¥
```bash
# å¦‚æœç›£æ§è…³æœ¬é¡¯ç¤º EMA Dice é”åˆ° 0.70
# å¯ä»¥æ‰‹å‹•åœæ­¢è¨“ç·´ï¼š
PID=$(cat training_pid.txt)
kill -SIGINT $PID

# æˆ–ç­‰å¾…è‡ªå‹•åœæ­¢ï¼ˆmonitor_and_stop.sh æœƒè‡ªå‹•è™•ç†ï¼‰
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### å•é¡Œ 1ï¼šCUDA Out of Memory (OOM)
```bash
# ç—‡ç‹€ï¼šRuntimeError: CUDA out of memory
# è§£æ±ºæ–¹æ¡ˆï¼š
# 1. é™ä½ batch sizeï¼ˆå¾ 4 â†’ 2ï¼‰
# 2. æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºä½¿ç”¨ GPUï¼šnvidia-smi
# 3. é‡å•Ÿ Python é€²ç¨‹æ¸…é™¤å¿«å–
```

### å•é¡Œ 2ï¼šCheckpoint ç„¡æ³•è¼‰å…¥
```bash
# ç—‡ç‹€ï¼šæ‰¾ä¸åˆ° checkpoint æˆ–è¼‰å…¥å¤±æ•—
# ç¢ºèªæª”æ¡ˆå­˜åœ¨ï¼š
ls -lh nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/checkpoint_best.pth

# ç¢ºèªè·¯å¾‘æ­£ç¢ºï¼ˆnnU-Net æœƒè‡ªå‹•æœå°‹ï¼‰
# å¦‚æœé‚„æ˜¯å¤±æ•—ï¼Œå¯èƒ½éœ€è¦å¾ Epoch 0 é‡æ–°é–‹å§‹ï¼ˆæœƒå¿«å¾ˆå¤šï¼‰
```

### å•é¡Œ 3ï¼šè¨“ç·´é€Ÿåº¦æ²’æœ‰æ˜é¡¯æå‡
```bash
# å¯èƒ½åŸå› ï¼š
# 1. ä½¿ç”¨äº† CPU è€Œé GPU
python -c "import torch; print(torch.cuda.is_available())"  # æ‡‰ç‚º True

# 2. I/O ç“¶é ¸ï¼ˆç£ç¢Ÿè®€å–æ…¢ï¼‰
# è§£æ±ºï¼šå°‡è³‡æ–™è¤‡è£½åˆ° NVMe SSD

# 3. batch_size å¤ªå°
# è§£æ±ºï¼šå¢åŠ  batch_size åˆ° 4 æˆ– 6
```

### å•é¡Œ 4ï¼šSSH æ–·ç·šå°è‡´è¨“ç·´ä¸­æ–·
```bash
# é é˜²æ–¹æ¡ˆï¼š
# ä½¿ç”¨ tmux æˆ– nohupï¼ˆè¦‹ Step 6ï¼‰

# å¦‚æœå·²ä¸­æ–·ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰ checkpointï¼š
ls -lt nnUNet_results/Dataset001_CardiacSeg/nnUNetTrainer__nnUNetPlans__3d_lowres/fold_0/checkpoint_*.pth

# é‡æ–°å•Ÿå‹•ï¼ˆæœƒå¾æœ€å¾Œçš„ checkpoint ç¹¼çºŒï¼‰
nnUNetv2_train 001 3d_lowres 0 -p nnUNetPlans -device cuda --c
```

---

## âœ… å®Œæˆæª¢æŸ¥æ¸…å–®

é·ç§»å‰ï¼ˆmacOSï¼‰ï¼š
- [ ] ç¢ºèªè¨“ç·´åˆ° Epoch 4-5
- [ ] å»ºç«‹ checkpoint æ‰“åŒ…æª”ï¼ˆnnunet_checkpoint_epoch5.tar.gzï¼‰
- [ ] é©—è­‰æ‰“åŒ…æª”å®Œæ•´æ€§ï¼ˆ1.0 GBï¼‰
- [ ] åœæ­¢ macOS è¨“ç·´é€²ç¨‹
- [ ] å‚³è¼¸æª”æ¡ˆåˆ° RTX 4090 æ©Ÿå™¨

RTX 4090 æ©Ÿå™¨è¨­å®šï¼š
- [ ] ç¢ºèª CUDA å¯ç”¨ï¼ˆnvidia-smiï¼‰
- [ ] å»ºç«‹ Python è™›æ“¬ç’°å¢ƒï¼ˆPython 3.11ï¼‰
- [ ] å®‰è£ PyTorch with CUDA
- [ ] å®‰è£ nnU-Net v2
- [ ] è¨­å®š nnU-Net ç’°å¢ƒè®Šæ•¸
- [ ] è§£å£“ checkpoint ä¸¦é©—è­‰
- [ ] ï¼ˆå¯é¸ï¼‰èª¿æ•´ batch size

å•Ÿå‹•è¨“ç·´ï¼š
- [ ] ä½¿ç”¨ tmux/screen æˆ– nohup èƒŒæ™¯åŸ·è¡Œ
- [ ] ç¢ºèªè¨“ç·´å¾ Epoch 5 ç¹¼çºŒï¼ˆ--c åƒæ•¸ï¼‰
- [ ] å•Ÿå‹•è‡ªå‹•ç›£æ§è…³æœ¬
- [ ] æª¢æŸ¥ GPU ä½¿ç”¨ç‡ï¼ˆæ‡‰æ¥è¿‘ 100%ï¼‰
- [ ] ç¢ºèªé¦–å€‹ epoch æ™‚é–“ï¼ˆæ‡‰ ~26 åˆ†é˜ï¼‰

ç›£æ§èˆ‡å„ªåŒ–ï¼š
- [ ] æ¯ 2-4 å°æ™‚æª¢æŸ¥é€²åº¦
- [ ] ç›£æ§ GPU æº«åº¦ï¼ˆ<85Â°Cï¼‰
- [ ] æŸ¥çœ‹ loss ä¸‹é™è¶¨å‹¢
- [ ] åœ¨ EMA Dice 0.70 æ™‚è©•ä¼°æ˜¯å¦åœæ­¢

---

## ğŸ“ éœ€è¦å”åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°å•é¡Œï¼Œæä¾›ä»¥ä¸‹è³‡è¨Šï¼š
1. éŒ¯èª¤è¨Šæ¯ï¼ˆå®Œæ•´ tracebackï¼‰
2. `nvidia-smi` è¼¸å‡º
3. Python èˆ‡ PyTorch ç‰ˆæœ¬
4. æœ€æ–°è¨“ç·´æ—¥èªŒçš„æœ€å¾Œ 50 è¡Œ
5. nnU-Net ç‰ˆæœ¬ï¼š`pip show nnunetv2`

---

## ğŸ¯ ç¸½çµ

### é·ç§»å„ªå‹¢
- âš¡ **4å€é€Ÿåº¦æå‡**ï¼šå¾ 5.5 å¤© â†’ 1.4 å¤©
- ğŸ’° **ç¯€çœ 98 å°æ™‚**ï¼šææ—© 4 å¤©å®Œæˆ
- ğŸ¯ **æ›´å¿«è¿­ä»£**ï¼šå¯ä»¥æ›´å¿«æ¸¬è©¦ä¸åŒé…ç½®
- ğŸ“Š **æ›´å¥½ç¡¬é«”**ï¼šåŸç”Ÿ CUDA å„ªåŒ–ï¼Œæ›´ç©©å®š

### é æœŸçµæœ
- Epoch 10ï¼šç´„ 2 å°æ™‚å¾Œå®Œæˆ
- Epoch 40ï¼šç´„ 15 å°æ™‚å¾Œå®Œæˆ
- **é”åˆ° Dice 0.70**ï¼šé ä¼° 20-24 å°æ™‚
- å®Œæ•´ 80 epochsï¼šç´„ 33 å°æ™‚ï¼ˆ1.4 å¤©ï¼‰

### ä¸‹ä¸€æ­¥
1. å‚³è¼¸ checkpoint åˆ° RTX 4090 æ©Ÿå™¨
2. æŒ‰ç…§æœ¬æŒ‡å—è¨­å®šç’°å¢ƒ
3. å•Ÿå‹•è¨“ç·´ä¸¦ç›£æ§
4. åœ¨é”åˆ°ç›®æ¨™ Dice æ™‚åœæ­¢æˆ–ç¹¼çºŒåˆ° 80 epochs

**ç¥è¨“ç·´é †åˆ©ï¼ğŸš€**
